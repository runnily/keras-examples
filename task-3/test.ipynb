{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1645745311379
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing \n",
        "This section allows you to test the model.\n",
        "Feel free to change the value of \"prev_word\" which specifies the previous words and \"next_words\" which specifcies the next words"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prev_words = \"As I stood hesitating in the hall\"\n",
        "next_words = \"with all this passing through my mind,\"\n",
        "next_words = len(next_words.split())"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1645745311971
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(\"h5-model-3.h5\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2022-02-24 23:28:32.580337: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-02-24 23:28:46.222401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7429 MB memory:  -> device: 0, name: Tesla M60, pci bus id: 0001:00:00.0, compute capability: 5.2\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1645745328221
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_data(filename=\"poirotInvestigates.txt\"):\n",
        "    \"\"\"\n",
        "        This function will simply open the file and read in the text. The text\n",
        "        will be converted in to lower case characters. It then removes all characters\n",
        "        which are digits.\n",
        "    \"\"\"\n",
        "    lines = []\n",
        "    with open(filename) as file:\n",
        "        lines = [line for line in file if line != \"\\n\"]\n",
        "    \n",
        "    for i in range(len(lines)):\n",
        "        edit_line = lines[i].replace(\"\\n\", \"\")\n",
        "        edit_line = edit_line.replace(\"***\", \" \")\n",
        "        edit_line = edit_line.replace(\"_\", \"\")\n",
        "        edit_line = edit_line.replace('”', \"\")\n",
        "        edit_line = edit_line.replace('“', \"\")\n",
        "        lines[i] = edit_line.lower()\n",
        "        \n",
        "    return lines\n"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1645745328538
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(prev_word, next_words): \n",
        "  \"\"\"\n",
        "  Perform the prediction of the next words\n",
        "\n",
        "  \"\"\"\n",
        "  token = Tokenizer()\n",
        "  token.fit_on_texts(get_data())\n",
        "  max_seqence_len = 17\n",
        "  model = load_model(\"h5-model-3.h5\")\n",
        "\n",
        "  for _ in range(next_words):\n",
        "    token_list = token.texts_to_sequences([prev_word])[0] # convert next_word to sequence\n",
        "    token_list = pad_sequences([token_list], maxlen=max_seqence_len-1, padding='pre') # add padding\n",
        "    predicted = np.argmax(model.predict(token_list, verbose=1), axis=-1)\n",
        "    ouput_word = \"\"\n",
        "    for word, index in token.word_index.items():\n",
        "        if index == predicted:\n",
        "          output_word = word\n",
        "          break\n",
        "    prev_word += ' '+ output_word\n",
        "  print(prev_word)\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1645745328770
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(prev_words, next_words)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2022-02-24 23:29:00.262761: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8101\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "1/1 [==============================] - 25s 25s/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 23ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 18ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 32ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nAs I stood hesitating in the hall poirot with that appearance the man had\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1645745355416
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}